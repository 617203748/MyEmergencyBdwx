											Hadoop集群
实验环境
	1）Centos_6.8_x64
	2）hadoop_2.2.0_x64
	3）jdk_1.8_u112_x64
	4) mysql_5.6.34
	
	
一、准备环境
	三台服务器全部装好 jdk 和 Hadoop
	node0 为 nodename
	node1 为 nodedata
	node2 为 nodedata
	
	分别修改 /etc/hosts 加上
		172.16.105.159          node0
		172.16.105.139          node1
		172.16.159.149          node2



		
# mkdir /mydata/setup/hadoop-2.2.0/tmp
# mkdir /mydata/setup/hadoop-2.2.0/dfs
# mkdir /mydata/setup/hadoop-2.2.0/dfs/name
# mkdir /mydata/setup/hadoop-2.2.0/dfs/data
												
# cd /mydata/setup/hadoop-2.2.0/etc/hadoop


一、配置node0
	1、配置$HADOOP_HOME/etc/hadoop/目录中如下的配置文件：
	    1) vim hadoop-env.sh
	       export JAVA_HOME=/mydata/java/jdk1.8.0_112
	
	    2) vim core-site.xml
	       注：如果没有hddata/tmp目录，要先在磁盘上创建。
		   <configuration>
				<property>
					<name>fs.defaultFS</name>
					<value>hdfs://localhost:9000/</value>
				</property>
				<property>
					<name>hadoop.tmp.dir</name>
					<value>/mydata/setup/hadoop2.2.0/tmp</value>
				</property>
				<property>
					<name>io.file.buffer.size</name>
					<value>131702</value>
				</property>
			</configuration>
	
	    3) vim hdfs-site.xml
	       注：如果没有hddata/name目录和hddata/data目录，要先在磁盘上创建。
	       <configuration>
				<property>
					<name>dfs.namenode.name.dir</name>
					<value>/mydata/setup/hadoop2.2.0/dfs/name</value>
				</property>
				<property>
					<name>dfs.datanode.data.dir</name>
					<value>/mydata/setup/hadoop2.2.0/dfs/data</value>
				</property>
				<property>
					<name>dfs.replication</name>
					<value>3</value>
				</property>
	       </configuration>
	
	    4) cp mapred-site.xml.template mapred-site.xml
	       vim mapred-site.xml
	       注：默认没有这个文件，从mapred-site.xml.template复制一份并改名。
		<configuration>
			<property>
				<name>mapreduce.framework.name</name>
		                <value>yarn</value>
			</property>
			<!-- 配置 MapReduce JobHistory Server 地址 ，默认端口10020 -->
		    	<property>
		            <name>mapreduce.jobhistory.address</name>
		            <value>localhost:10020</value>
		    	</property>
			<!-- 配置 MapReduce JobHistory Server web ui 地址， 默认端口19888 -->
		    	<property>
		            <name>mapreduce.jobhistory.webapp.address</name>
		            <value>localhost:19888</value>
		     	</property>
		</configuration>
	
	    5) vim yarn-site.xml
		<configuration>
			<property>
				<name>yarn.nodemanager.aux-services</name>
				<value>mapreduce_shuffle</value>
			</property>
			<property>
				<name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
				<value>org.apache.hadoop.mapred.ShuffleHandler</value>
			</property>
			<property>
				<name>yarn.resourcemanager.hostname</name>
				<value>localhost</value>
			</property>
		</configuration>
		
		6)slaves 集群分节点
	
	2、格式化hdfs(仅需执行格式化一次)。在终端窗口，执行命令:
	   $ hdfs namenode -format
	   
	   
二、配置node1
	1、配置$HADOOP_HOME/etc/hadoop/目录中如下的配置文件：
	    1) vim hadoop-env.sh
	       export JAVA_HOME=/mydata/java/jdk1.8.0_112
	
	    2) vim core-site.xml
	       注：如果没有hddata/tmp目录，要先在磁盘上创建。
		   <configuration>
				<property>
					<!-- 集群的主节点 -->
					<name>fs.defaultFS</name>
					<value>hdfs://node0:9000/</value>
				</property>
				<property>
					<name>hadoop.tmp.dir</name>
					<value>/mydata/setup/hadoop2.2.0/tmp</value>
				</property>
				<property>
					<name>io.file.buffer.size</name>
					<value>131702</value>
				</property>
			</configuration>
	
	    3) vim hdfs-site.xml
	       注：如果没有hddata/name目录和hddata/data目录，要先在磁盘上创建。
	       <configuration>
				<property>
					<name>dfs.namenode.name.dir</name>
					<value>/mydata/setup/hadoop2.2.0/dfs/name</value>
				</property>
				<property>
					<name>dfs.datanode.data.dir</name>
					<value>/mydata/setup/hadoop2.2.0/dfs/data</value>
				</property>
				<property>
					<name>dfs.replication</name>
					<value>3</value>
				</property>
	       </configuration>
	
	    4) cp mapred-site.xml.template mapred-site.xml
	       vim mapred-site.xml
	       注：默认没有这个文件，从mapred-site.xml.template复制一份并改名。
		<configuration>
			<property>
				<name>mapreduce.framework.name</name>
		                <value>yarn</value>
			</property>
			<!-- 配置 MapReduce JobHistory Server 地址 ，默认端口10020 -->
		    	<property>
		            <name>mapreduce.jobhistory.address</name>
		            <value>localhost:10020</value>
		    	</property>
			<!-- 配置 MapReduce JobHistory Server web ui 地址， 默认端口19888 -->
		    	<property>
		            <name>mapreduce.jobhistory.webapp.address</name>
		            <value>localhost:19888</value>
		     	</property>
		</configuration>
	
	    5) vim yarn-site.xml
		<configuration>
			<property>
				<name>yarn.nodemanager.aux-services</name>
				<value>mapreduce_shuffle</value>
			</property>
			<property>
				<name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
				<value>org.apache.hadoop.mapred.ShuffleHandler</value>
			</property>
			<property>
				<!-- 如果是集群的话 这里是集群主机的IP -->
				<name>yarn.resourcemanager.hostname</name>
				<value>node0</value>
			</property>
		</configuration>
